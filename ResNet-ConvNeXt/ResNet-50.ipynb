{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyOzKi+zCXpX4kLXIN7j87DR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dracLD5WSNt4","executionInfo":{"status":"ok","timestamp":1744834516223,"user_tz":-180,"elapsed":5076370,"user":{"displayName":"Konstantinos Roumeliotis","userId":"17264923090131634662"}},"outputId":"a98c29f5-3e95-4073-b899-dbbc6c5edf6c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting optuna\n","  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.1)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n","Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n","Mounted at /content/gdrive\n"]},{"output_type":"stream","name":"stderr","text":["[I 2025-04-16 18:51:14,094] A new study created in RDB with name: resnet_optimization\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 180MB/s]\n","Training: 100%|██████████| 53/53 [00:58<00:00,  1.11s/it]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.88it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.34it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.35it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.88it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.78it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.50it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.13it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.21it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.29it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.71it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 14.06it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.09it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.84it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.10it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.37it/s]\n","[I 2025-04-16 18:53:41,595] Trial 0 finished with value: 0.5226998001998001 and parameters: {'learning_rate': 5.6115164153345e-05, 'batch_size': 16, 'image_size': 400}. Best is trial 0 with value: 0.5226998001998001.\n","Training: 100%|██████████| 4/4 [00:07<00:00,  1.75s/it]\n","Training: 100%|██████████| 4/4 [00:05<00:00,  1.45s/it]\n","Training: 100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.53s/it]\n","Training: 100%|██████████| 4/4 [00:05<00:00,  1.47s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.55s/it]\n","[I 2025-04-16 18:54:33,065] Trial 1 pruned. \n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.58s/it]\n","Training: 100%|██████████| 4/4 [00:05<00:00,  1.49s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.53s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.53s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.59s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.54s/it]\n","[I 2025-04-16 18:55:25,313] Trial 2 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.59it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.62it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.64it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.69it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.49it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.60it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.44it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.64it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.66it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.57it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.64it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.48it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.72it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.43it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.72it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.55it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.61it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.71it/s]\n","[I 2025-04-16 18:57:00,706] Trial 3 finished with value: 0.5251408922461553 and parameters: {'learning_rate': 7.309539835912905e-05, 'batch_size': 32, 'image_size': 400}. Best is trial 3 with value: 0.5251408922461553.\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.38it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.89it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.18it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.45it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.89it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.62it/s]\n","[I 2025-04-16 18:57:31,071] Trial 4 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.43it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.43it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.43it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.42it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.40it/s]\n","[I 2025-04-16 18:58:34,559] Trial 5 finished with value: 0.5044729671200259 and parameters: {'learning_rate': 0.000164092867306479, 'batch_size': 128, 'image_size': 400}. Best is trial 3 with value: 0.5251408922461553.\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.69it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.59it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.66it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.54it/s]\n","Training: 100%|██████████| 27/27 [00:03<00:00,  6.86it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.39it/s]\n","[I 2025-04-16 18:59:06,594] Trial 6 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.97it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.59it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.90it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 14.01it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.17it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.99it/s]\n","[I 2025-04-16 18:59:36,509] Trial 7 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.67it/s]\n","Training: 100%|██████████| 27/27 [00:03<00:00,  6.84it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.59it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.66it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.57it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.38it/s]\n","[I 2025-04-16 19:00:08,692] Trial 8 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.59it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.53it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.73it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 14.02it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.11it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.72it/s]\n","[I 2025-04-16 19:00:38,984] Trial 9 pruned. \n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.04it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.13it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.12it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.15it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.14it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.14it/s]\n","[I 2025-04-16 19:01:14,801] Trial 10 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.62it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.74it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.64it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.69it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.65it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.36it/s]\n","[I 2025-04-16 19:01:46,838] Trial 11 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","[I 2025-04-16 19:02:29,521] Trial 12 pruned. \n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.02it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.10it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  2.97it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.11it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.01it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.11it/s]\n","[I 2025-04-16 19:03:06,204] Trial 13 pruned. \n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.13it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.66it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.30it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.45it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.86it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.85it/s]\n","[I 2025-04-16 19:03:36,980] Trial 14 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.52it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.57it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.49it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.61it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.69it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.66it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.37it/s]\n","Training: 100%|██████████| 27/27 [00:03<00:00,  6.76it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.44it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.72it/s]\n","[I 2025-04-16 19:04:30,497] Trial 15 finished with value: 0.46214015287544696 and parameters: {'learning_rate': 7.012110566730138e-05, 'batch_size': 32, 'image_size': 400}. Best is trial 3 with value: 0.5251408922461553.\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.46it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.44it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.70it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.49it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.56it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.21it/s]\n","[I 2025-04-16 19:05:03,313] Trial 16 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.51it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.20it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.86it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.26it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.41it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.29it/s]\n","[I 2025-04-16 19:05:34,086] Trial 17 pruned. \n","Training: 100%|██████████| 14/14 [00:04<00:00,  2.96it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.15it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  2.96it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.14it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  2.90it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.13it/s]\n","[I 2025-04-16 19:06:10,832] Trial 18 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","[I 2025-04-16 19:06:53,942] Trial 19 pruned. \n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.58s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.61s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.66s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.62s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.51s/it]\n","[I 2025-04-16 19:07:47,508] Trial 20 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.30it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","[I 2025-04-16 19:08:31,501] Trial 21 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","[I 2025-04-16 19:09:14,916] Trial 22 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s]\n","[I 2025-04-16 19:09:58,770] Trial 23 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.43it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.42it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.43it/s]\n","[I 2025-04-16 19:12:14,008] Trial 24 finished with value: 0.5333786583786584 and parameters: {'learning_rate': 8.882934298549312e-05, 'batch_size': 128, 'image_size': 400}. Best is trial 24 with value: 0.5333786583786584.\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.12it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.56it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.61it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.32it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.49it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.99it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.78it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.66it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.99it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.47it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.92it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.59it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.60it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.75it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.33it/s]\n","[I 2025-04-16 19:13:30,109] Trial 25 finished with value: 0.49142228142228145 and parameters: {'learning_rate': 3.113296068946989e-05, 'batch_size': 16, 'image_size': 400}. Best is trial 24 with value: 0.5333786583786584.\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.46it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.48it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.34it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.58it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.39it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.48it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.46it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.54it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.58it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.42it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.53it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.29it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.54it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.50it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.56it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.60it/s]\n","[I 2025-04-16 19:14:56,798] Trial 26 finished with value: 0.5053724199776831 and parameters: {'learning_rate': 5.780071132767434e-05, 'batch_size': 32, 'image_size': 400}. Best is trial 24 with value: 0.5333786583786584.\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.47it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.53it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.37it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.53it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.32it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.57it/s]\n","[I 2025-04-16 19:15:29,598] Trial 27 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.25it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.71it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.41it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.00it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.67it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.96it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.22it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.35it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.88it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.58it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.17it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.23it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.39it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.64it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.63it/s]\n","[I 2025-04-16 19:16:46,050] Trial 28 finished with value: 0.5510829693182634 and parameters: {'learning_rate': 5.912650802943606e-05, 'batch_size': 16, 'image_size': 400}. Best is trial 28 with value: 0.5510829693182634.\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.43it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.30it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","[I 2025-04-16 19:19:24,021] Trial 29 finished with value: 0.49732008732008737 and parameters: {'learning_rate': 0.00010543464503934395, 'batch_size': 128, 'image_size': 400}. Best is trial 28 with value: 0.5510829693182634.\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.00it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.42it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.10it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.54it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.69it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.37it/s]\n","[I 2025-04-16 19:19:55,012] Trial 30 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.25it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.03it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.44it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.15it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.58it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.26it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.00it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.54it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.84it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.52it/s]\n","[I 2025-04-16 19:20:46,490] Trial 31 finished with value: 0.5756222481222482 and parameters: {'learning_rate': 5.936234651371578e-05, 'batch_size': 16, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.20it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.41it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.31it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.04it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.56it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.89it/s]\n","[I 2025-04-16 19:21:17,709] Trial 32 pruned. \n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.62s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.58s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.55s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.54s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.64s/it]\n","[I 2025-04-16 19:22:11,232] Trial 33 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.41it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.47it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.38it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.93it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.90it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.44it/s]\n","[I 2025-04-16 19:22:41,985] Trial 34 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.34it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.48it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.60it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.45it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.88it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.36it/s]\n","[I 2025-04-16 19:23:12,961] Trial 35 pruned. \n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.61s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.60s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.65s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.54s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\n","[I 2025-04-16 19:24:06,853] Trial 36 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.52it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.31it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.30it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.64it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.87it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.54it/s]\n","[I 2025-04-16 19:24:37,755] Trial 37 pruned. \n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.04it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.04it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.07it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.11it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.05it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.09it/s]\n","[I 2025-04-16 19:25:14,521] Trial 38 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.40it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.65it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.63it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.43it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.48it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.37it/s]\n","[I 2025-04-16 19:25:47,397] Trial 39 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.66it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.01it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.13it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.51it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.08it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.65it/s]\n","[I 2025-04-16 19:26:18,330] Trial 40 pruned. \n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.99it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.77it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.16it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.60it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.63it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.03it/s]\n","[I 2025-04-16 19:26:49,300] Trial 41 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.58it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.12it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.75it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.36it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.51it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.77it/s]\n","[I 2025-04-16 19:27:19,868] Trial 42 pruned. \n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.10it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.86it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.96it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.53it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.54it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.42it/s]\n","[I 2025-04-16 19:27:50,736] Trial 43 pruned. \n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","[I 2025-04-16 19:29:02,516] Trial 44 finished with value: 0.45734382364817144 and parameters: {'learning_rate': 0.00013903136292441927, 'batch_size': 128, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.83it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.28it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.58it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.50it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.15it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.50it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.09it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.60it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.79it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.14it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.75it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.14it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.79it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.64it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.42it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.47it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.13it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.32it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.36it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.68it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.81it/s]\n","[I 2025-04-16 19:30:48,587] Trial 45 finished with value: 0.5318657703951821 and parameters: {'learning_rate': 3.098832955016992e-05, 'batch_size': 16, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.14it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.46it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.97it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.73it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.69it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.42it/s]\n","[I 2025-04-16 19:31:19,483] Trial 46 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.58it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.39it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.54it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.39it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.56it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.56it/s]\n","[I 2025-04-16 19:31:52,334] Trial 47 pruned. \n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.66s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.51s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.57s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.50s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.58s/it]\n","[I 2025-04-16 19:32:45,422] Trial 48 pruned. \n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.08it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.06it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.05it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.14it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.07it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.06it/s]\n","[I 2025-04-16 19:33:22,087] Trial 49 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.30it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.40it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.39it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.12it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.65it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.35it/s]\n","[I 2025-04-16 19:33:53,209] Trial 50 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.42it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.53it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.86it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.34it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.05it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.52it/s]\n","[I 2025-04-16 19:34:24,245] Trial 51 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.61it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.43it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.20it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.84it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.36it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.42it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.49it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.52it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.98it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.54it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.20it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.84it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.51it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.98it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.80it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.84it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.64it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.57it/s]\n","[I 2025-04-16 19:35:55,837] Trial 52 finished with value: 0.5254376179376178 and parameters: {'learning_rate': 7.699840215030367e-05, 'batch_size': 16, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.62it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.80it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.95it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.62it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.28it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.10it/s]\n","[I 2025-04-16 19:36:26,824] Trial 53 pruned. \n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.21it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.45it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.51it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.79it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.37it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.23it/s]\n","[I 2025-04-16 19:36:58,063] Trial 54 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","[I 2025-04-16 19:37:41,614] Trial 55 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.41it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.61it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.65it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.47it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.65it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.34it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.47it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.35it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.58it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.55it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.63it/s]\n","[I 2025-04-16 19:38:41,299] Trial 56 finished with value: 0.5171834701246466 and parameters: {'learning_rate': 6.41057411380081e-05, 'batch_size': 32, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.47it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.51it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.39it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.91it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.76it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.26it/s]\n","[I 2025-04-16 19:39:12,339] Trial 57 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.57it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.48it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.63it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.51it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.39it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.69it/s]\n","[I 2025-04-16 19:39:45,118] Trial 58 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.43it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","[I 2025-04-16 19:42:23,433] Trial 59 finished with value: 0.5290656711709342 and parameters: {'learning_rate': 0.00011925997496517254, 'batch_size': 128, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","[I 2025-04-16 19:43:35,287] Trial 60 finished with value: 0.5140903102745208 and parameters: {'learning_rate': 0.00014315424188650458, 'batch_size': 128, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n","[I 2025-04-16 19:44:19,189] Trial 61 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","[I 2025-04-16 19:45:45,740] Trial 62 finished with value: 0.47225729608082556 and parameters: {'learning_rate': 0.00012110156550525946, 'batch_size': 128, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.42it/s]\n","[I 2025-04-16 19:46:29,391] Trial 63 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.30it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","[I 2025-04-16 19:47:13,100] Trial 64 pruned. \n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.19it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.60it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.50it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.27it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.51it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.85it/s]\n","[I 2025-04-16 19:47:44,214] Trial 65 pruned. \n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.04it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  2.93it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.07it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  2.95it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.07it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  2.94it/s]\n","[I 2025-04-16 19:48:21,693] Trial 66 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.67it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.79it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.79it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.57it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.37it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.71it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.09it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.32it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.13it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.49it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.52it/s]\n","[I 2025-04-16 19:49:18,122] Trial 67 finished with value: 0.501296497620027 and parameters: {'learning_rate': 9.256590177981417e-05, 'batch_size': 16, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.35it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.59it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.32it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.51it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.55it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.59it/s]\n","[I 2025-04-16 19:49:51,099] Trial 68 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","[I 2025-04-16 19:50:56,312] Trial 69 finished with value: 0.4903993446640505 and parameters: {'learning_rate': 0.00023460963879664093, 'batch_size': 128, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.60s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.62s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.56s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.60s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.62s/it]\n","[I 2025-04-16 19:51:50,395] Trial 70 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.32it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.80it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.18it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.02it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.55it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.31it/s]\n","[I 2025-04-16 19:52:21,863] Trial 71 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.25it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.30it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.96it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.31it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.19it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.50it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.65it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.15it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.25it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.04it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.27it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.43it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.45it/s]\n","[I 2025-04-16 19:53:28,800] Trial 72 finished with value: 0.4959540622775917 and parameters: {'learning_rate': 5.942386642703737e-05, 'batch_size': 16, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.64it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.07it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.43it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.32it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.70it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.84it/s]\n","[I 2025-04-16 19:53:59,728] Trial 73 pruned. \n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.20it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.54it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.22it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.39it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.42it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.44it/s]\n","[I 2025-04-16 19:54:30,807] Trial 74 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.46it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.05it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.48it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.84it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.06it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.17it/s]\n","[I 2025-04-16 19:55:02,215] Trial 75 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.41it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.75it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.76it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.61it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.14it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.84it/s]\n","[I 2025-04-16 19:55:33,212] Trial 76 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.37it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.61it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.54it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.50it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.64it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.35it/s]\n","[I 2025-04-16 19:56:06,137] Trial 77 pruned. \n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.31it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.42it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","[I 2025-04-16 19:56:49,515] Trial 78 pruned. \n","Training: 100%|██████████| 14/14 [00:04<00:00,  2.99it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.11it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  2.88it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.09it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  2.92it/s]\n","Training: 100%|██████████| 14/14 [00:04<00:00,  3.08it/s]\n","[I 2025-04-16 19:57:26,765] Trial 79 pruned. \n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.03it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.52it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.09it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.76it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.33it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.11it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.32it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.97it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.42it/s]\n","[I 2025-04-16 19:58:13,443] Trial 80 finished with value: 0.48886811989753165 and parameters: {'learning_rate': 0.00010004437960844984, 'batch_size': 16, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.45it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.66it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.57it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.42it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.61it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.32it/s]\n","[I 2025-04-16 19:58:46,460] Trial 81 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.46it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.21it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.51it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.49it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.65it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.58it/s]\n","[I 2025-04-16 19:59:19,606] Trial 82 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.61it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.68it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.45it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.56it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.35it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.64it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.35it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.58it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.51it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.47it/s]\n","[I 2025-04-16 20:00:14,055] Trial 83 finished with value: 0.5683052619894724 and parameters: {'learning_rate': 0.00011280483243627007, 'batch_size': 32, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.61it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.47it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.71it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.37it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.57it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.58it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.43it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.57it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.52it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.56it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.44it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.59it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.46it/s]\n","[I 2025-04-16 20:01:24,878] Trial 84 finished with value: 0.5183157583157583 and parameters: {'learning_rate': 0.00014512516911572432, 'batch_size': 32, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.45it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.28it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.73it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.50it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.51it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.66it/s]\n","[I 2025-04-16 20:01:57,997] Trial 85 pruned. \n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.64s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.60s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.62s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.62s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.62s/it]\n","Training: 100%|██████████| 4/4 [00:06<00:00,  1.63s/it]\n","[I 2025-04-16 20:02:52,776] Trial 86 pruned. \n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.22it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.17it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.50it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.60it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.52it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.46it/s]\n","[I 2025-04-16 20:03:24,152] Trial 87 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.40it/s]\n","[I 2025-04-16 20:04:36,592] Trial 88 finished with value: 0.523105598105598 and parameters: {'learning_rate': 0.00015741634071811722, 'batch_size': 128, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","[I 2025-04-16 20:05:20,348] Trial 89 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","[I 2025-04-16 20:06:03,887] Trial 90 pruned. \n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.30it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.42it/s]\n","[I 2025-04-16 20:06:47,403] Trial 91 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","[I 2025-04-16 20:07:31,466] Trial 92 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.35it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.01it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.44it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.11it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.42it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.25it/s]\n","[I 2025-04-16 20:08:02,846] Trial 93 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.41it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.38it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","[I 2025-04-16 20:08:46,385] Trial 94 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.52it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.39it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.53it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.32it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.47it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.19it/s]\n","[I 2025-04-16 20:09:19,795] Trial 95 pruned. \n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.57it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.13it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.44it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.54it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.02it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.60it/s]\n","[I 2025-04-16 20:09:50,932] Trial 96 pruned. \n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.33it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.35it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.37it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n","Training: 100%|██████████| 7/7 [00:04<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.40it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.32it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.39it/s]\n","Training: 100%|██████████| 7/7 [00:05<00:00,  1.34it/s]\n","[I 2025-04-16 20:11:25,073] Trial 97 finished with value: 0.521845050374462 and parameters: {'learning_rate': 0.00010925820097250137, 'batch_size': 128, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.53it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.35it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.42it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.99it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.57it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.41it/s]\n","[I 2025-04-16 20:11:56,149] Trial 98 pruned. \n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.68it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.58it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.46it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.62it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.22it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.54it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.41it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.52it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.51it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.67it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.62it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.43it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.64it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.34it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.65it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.34it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.68it/s]\n","Training: 100%|██████████| 27/27 [00:04<00:00,  6.38it/s]\n","[I 2025-04-16 20:13:33,929] Trial 99 finished with value: 0.5114178305354775 and parameters: {'learning_rate': 5.646680966367406e-05, 'batch_size': 32, 'image_size': 400}. Best is trial 31 with value: 0.5756222481222482.\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.80it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.55it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.64it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.79it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.21it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.88it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.09it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.82it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.41it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.91it/s]\n","Training: 100%|██████████| 53/53 [00:05<00:00, 10.04it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.62it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.05it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 13.11it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.61it/s]\n","Training: 100%|██████████| 53/53 [00:04<00:00, 12.91it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.72it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.74it/s]\n","Training: 100%|██████████| 53/53 [00:03<00:00, 13.28it/s]\n"]}],"source":["!pip install optuna\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","import pandas as pd\n","import requests\n","from io import BytesIO\n","import time\n","from tqdm import tqdm\n","import os\n","import logging\n","import gc\n","import json\n","from datetime import datetime\n","import numpy as np\n","from sklearn.metrics import precision_recall_fscore_support\n","import multiprocessing\n","import optuna\n","from optuna.trial import TrialState\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Setup logging\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    handlers=[\n","        logging.FileHandler('training.log'),\n","        logging.StreamHandler()\n","    ]\n",")\n","logger = logging.getLogger(__name__)\n","\n","def save_best_model(model, label_to_idx, config, val_metrics, epoch, best_val_loss, best_model_filename):\n","    if val_metrics['loss'] < best_val_loss:\n","        best_val_loss = val_metrics['loss']\n","\n","        # Create the directory if it doesn't exist\n","        model_dir = os.path.join(config['paths']['absolute_path'], 'ResNet-Trained-Models/')\n","        os.makedirs(model_dir, exist_ok=True)\n","\n","        config_filename = f\"model_lr_{config['hyperparameters']['learning_rate']}_bs_{config['hyperparameters']['batch_size']}_es_{config['hyperparameters']['image_size']}.pth\"\n","        model_path = os.path.join(config['paths']['absolute_path']+'ResNet-Trained-Models/', config_filename)\n","\n","        torch.save(model.state_dict(), model_path)\n","\n","        label_to_idx_filename = model_path.replace('.pth', '_label_to_idx.json')\n","        with open(label_to_idx_filename, 'w') as f:\n","            json.dump(label_to_idx, f)\n","\n","        logger.info(f\"Best model saved at epoch {epoch} with loss {val_metrics['loss']}\")\n","\n","    return best_val_loss\n","\n","class Config:\n","    @staticmethod\n","    def validate_config(config):\n","        \"\"\"\n","        Validates the provided configuration to ensure all necessary paths, files, and parameters are correctly defined.\n","        - Checks for required paths and files in the dataset.\n","        - Ensures that hyperparameters like batch size, learning rate, and image size are positive.\n","        \"\"\"\n","\n","        required_paths = ['absolute_path', 'dataset_path']\n","        required_files = ['train_file', 'validation_file']\n","        required_columns = ['feature_col', 'label_col']\n","\n","        # Validate paths\n","        for path in required_paths:\n","            if not os.path.exists(config['paths'][path]):\n","                raise ValueError(f\"Path not found: {config['paths'][path]}\")\n","\n","        # Validate files\n","        for file in required_files:\n","            file_path = os.path.join(config['paths']['dataset_path'], config['filenames'][file])\n","            if not os.path.exists(file_path):\n","                raise ValueError(f\"File not found: {file_path}\")\n","\n","        # Validate hyperparameters\n","        if config['hyperparameters']['batch_size'] <= 0:\n","            raise ValueError(\"Batch size must be positive\")\n","        if config['hyperparameters']['learning_rate'] <= 0:\n","            raise ValueError(\"Learning rate must be positive\")\n","        if config['hyperparameters']['image_size'] <= 0:\n","            raise ValueError(\"Image size must be positive\")\n","\n","        return True\n","\n","class CustomImageDataset(Dataset):\n","    \"\"\"\n","    A custom PyTorch Dataset for loading images from local files on Google Drive.\n","    \"\"\"\n","\n","    def __init__(self, csv_file, config, transform=None):\n","        self.data = pd.read_csv(os.path.join(config['paths']['dataset_path'], csv_file))\n","        self.transform = transform\n","        self.feature_col = config['columns']['feature_col']\n","        self.label_col = config['columns']['label_col']\n","        self.classes = sorted(self.data[self.label_col].unique())\n","        self.label_to_idx = {label: idx for idx, label in enumerate(self.classes)}\n","        self.dataset_path = config['paths']['dataset_path']\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def _get_local_path_from_url(self, url):\n","        \"\"\"\n","        Convert a URL to a local file path.\n","        Example: https://applied-ai.gr/projects/computer-vision/400/1111786.jpg -> dataset_path/400/1111786.jpg\n","        \"\"\"\n","        # Extract the relevant part of the path from the URL\n","        # This assumes URLs follow a consistent pattern\n","        filename = url.split('/')[-1]  # Get the filename (e.g., 1111786.jpg)\n","        folder = url.split('/')[-2]    # Get the folder (e.g., 400)\n","\n","        # Construct the local path\n","        local_path = os.path.join(self.dataset_path, folder, filename)\n","        return local_path\n","\n","    def __getitem__(self, idx):\n","        try:\n","            img_url = self.data.iloc[idx][self.feature_col]\n","            label = self.data.iloc[idx][self.label_col]\n","\n","            # Get the local path from the URL\n","            local_path = self._get_local_path_from_url(img_url)\n","\n","            # Load the image from the local path\n","            img = Image.open(local_path).convert('RGB')\n","\n","            if self.transform:\n","                img = self.transform(img)\n","\n","            label_idx = self.label_to_idx[label]\n","            return img, label_idx\n","\n","        except Exception as e:\n","            logger.error(f\"Error loading image at index {idx}: {str(e)}\")\n","            logger.error(f\"URL: {img_url}, Local path: {local_path}\")\n","            raise\n","\n","def clear_gpu_memory():\n","    \"\"\"\n","    Clears GPU memory to avoid memory overflow issues during training.\n","    - Uses PyTorch's built-in functions to release GPU memory.\n","    \"\"\"\n","    if torch.cuda.is_available():\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","class ModelTrainer:\n","    def __init__(self, config):\n","        self.config = config\n","        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.metrics_history = []\n","        self.label_to_idx = None\n","\n","    # Prepares data augmentations and preprocessing steps for training and validation datasets.\n","    def _create_transforms(self):\n","        # Define transformations for the training dataset.\n","        # For our small dataset, more augmentations could help avoiding overfitting.\n","        # Each time an image is passed through the data loader,\n","        # these transformations are applied with randomized parameters.\n","        train_transform = transforms.Compose([\n","            # Resizes the image to a square defined by the configured image size.\n","            transforms.Resize((self.config['hyperparameters']['image_size'],\n","                           self.config['hyperparameters']['image_size'])),\n","            # Randomly flips the image horizontally.\n","            transforms.RandomHorizontalFlip(),\n","            # Randomly rotates the image by up to 15 degrees.\n","            transforms.RandomRotation(15),\n","            # Randomly changes the brightness, contrast, and saturation of the image.\n","            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","            transforms.ToTensor(), # Converts the image into a PyTorch tensor.\n","            # Normalizes the image using the specified mean\n","            # and standard deviation values (pre-trained model standards).\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                             std=[0.229, 0.224, 0.225])\n","        ])\n","\n","        # Define transformations for the validation dataset (no data augmentation).\n","        val_transform = transforms.Compose([\n","            transforms.Resize((self.config['hyperparameters']['image_size'],\n","                           self.config['hyperparameters']['image_size'])),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                             std=[0.229, 0.224, 0.225])\n","        ])\n","\n","        return train_transform, val_transform\n","\n","    # Creates PyTorch DataLoader objects for efficient data loading during training and validation.\n","    def _create_dataloaders(self, train_transform, val_transform):\n","        train_dataset = CustomImageDataset(\n","            self.config['filenames']['train_file'],\n","            self.config,\n","            transform=train_transform\n","        )\n","\n","        self.label_to_idx = train_dataset.label_to_idx  # Store the mapping\n","\n","        validation_dataset = CustomImageDataset(\n","            self.config['filenames']['validation_file'],\n","            self.config,\n","            transform=val_transform\n","        )\n","\n","        num_workers = min(multiprocessing.cpu_count(), 4)\n","\n","        train_loader = DataLoader(\n","            train_dataset,\n","            batch_size=self.config['hyperparameters']['batch_size'],\n","            shuffle=True,\n","            num_workers=num_workers,\n","            pin_memory=True\n","        )\n","\n","        validation_loader = DataLoader(\n","            validation_dataset,\n","            batch_size=self.config['hyperparameters']['batch_size'],\n","            shuffle=False,\n","            num_workers=num_workers,\n","            pin_memory=True\n","        )\n","\n","        return train_loader, validation_loader, train_dataset.classes\n","\n","    # Configures a ResNet50 model with fine-tuning of specific layers for the given number of classes.\n","    def _create_model(self, num_classes):\n","        # Loads a pre-trained ResNet-50 model with weights trained on the ImageNet dataset.\n","        model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n","        # Replaces the fully connected (fc) layer with a new sequential layer consisting of:\n","        # 1. Dropout layer (with a probability of 0.5) to reduce overfitting.\n","        # 2. Linear layer to adjust the output to match the number of classes in the dataset.\n","        model.fc = nn.Sequential(\n","            nn.Dropout(0.5),\n","            nn.Linear(model.fc.in_features, num_classes)\n","        )\n","        # Moves the model to the specified device (GPU) for training.\n","        model = model.to(self.device)\n","\n","        # Freezes the early layers of the model to prevent\n","        # their weights from being updated during training.\n","        for param in model.parameters():\n","            param.requires_grad = False\n","\n","        # Unfreezes the parameters of the final convolutional block (layer4)\n","        # to allow fine-tuning.\n","        for param in model.layer4.parameters():\n","            param.requires_grad = True\n","        for param in model.fc.parameters():\n","            param.requires_grad = True\n","\n","        return model\n","\n","    # Performs one epoch of training and computes training metrics like loss and accuracy.\n","    def _train_epoch(self, model, train_loader, criterion, optimizer):\n","        model.train()\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","        all_preds = [] # List to store all predicted labels for the epoch.\n","        all_labels = [] # List to store all true labels for the epoch.\n","\n","        # Loops through the training data loader batch by batch.\n","        for inputs, labels in tqdm(train_loader, desc='Training'):\n","            # Moves the inputs and labels to the configured device (GPU).\n","            inputs, labels = inputs.to(self.device), labels.to(self.device)\n","\n","            # Clears the gradients of the optimizer to prepare for the current batch.\n","            optimizer.zero_grad()\n","            # Passes the inputs through the model to obtain outputs (predictions).\n","            outputs = model(inputs)\n","            # Computes the loss between the predictions and the true labels.\n","            loss = criterion(outputs, labels)\n","            # Backpropagates the loss to compute gradients for all trainable parameters.\n","            loss.backward()\n","\n","            # Clips gradients to avoid exploding gradients during backpropagation.\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step() # Updates the model parameters using the optimizer.\n","\n","            # Accumulates the loss for reporting the average loss over the epoch.\n","            running_loss += loss.item()\n","            # Gets the predicted class labels for the batch by taking the index\n","            # of the maximum value in each output vector.\n","            _, predicted = torch.max(outputs.data, 1)\n","            # Updates the total number of labels and the count of correct\n","            # predictions for accuracy calculation.\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","            # Appends the predicted and true labels for this batch\n","            # to the lists for further analysis.\n","            all_preds.extend(predicted.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","        return {\n","            'loss': running_loss / len(train_loader),\n","            'accuracy': 100 * correct / total,\n","            'predictions': np.array(all_preds),\n","            'labels': np.array(all_labels)\n","        }\n","\n","    # Evaluates the model on the validation dataset and computes metrics like precision, recall, and F1-score.\n","    def _validate(self, model, validation_loader, criterion):\n","        model.eval()\n","        running_loss = 0.0\n","        correct = 0\n","        total = 0\n","        all_preds = []\n","        all_labels = []\n","\n","        with torch.no_grad():\n","            for inputs, labels in validation_loader:\n","                inputs, labels = inputs.to(self.device), labels.to(self.device)\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels)\n","\n","                running_loss += loss.item()\n","                _, predicted = torch.max(outputs.data, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","\n","                all_preds.extend(predicted.cpu().numpy())\n","                all_labels.extend(labels.cpu().numpy())\n","\n","        return {\n","            'loss': running_loss / len(validation_loader),\n","            'accuracy': 100 * correct / total,\n","            'predictions': np.array(all_preds),\n","            'labels': np.array(all_labels)\n","        }\n","\n","    def train(self, patience=4):\n","        try:\n","            train_transform, val_transform = self._create_transforms()\n","            train_loader, validation_loader, classes = self._create_dataloaders(\n","                train_transform, val_transform)\n","\n","            model = self._create_model(len(classes))\n","            criterion = nn.CrossEntropyLoss()\n","            optimizer = torch.optim.Adam([\n","                {'params': model.fc.parameters(),\n","                'lr': self.config['hyperparameters']['learning_rate'] * 10},\n","                {'params': model.layer4.parameters(),\n","                'lr': self.config['hyperparameters']['learning_rate']}\n","            ])\n","            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","                optimizer, mode='max', patience=1, factor=0.1)\n","\n","            best_val_loss = float('inf')\n","            early_stop_counter = 0\n","            epoch_metrics = []\n","\n","            # for epoch in range(self.config['hyperparameters']['num_epochs']):\n","            #     epoch_start = time.time()\n","\n","            #     train_metrics = self._train_epoch(model, train_loader, criterion, optimizer)\n","            #     clear_gpu_memory()\n","            #     val_metrics = self._validate(model, validation_loader, criterion)\n","            for epoch in range(self.config['hyperparameters']['num_epochs']):\n","                epoch_start = time.time()\n","\n","                train_metrics = self._train_epoch(model, train_loader, criterion, optimizer)\n","                clear_gpu_memory()\n","                val_metrics = self._validate(model, validation_loader, criterion)\n","\n","                precision, recall, f1, _ = precision_recall_fscore_support(\n","                    val_metrics['labels'],\n","                    val_metrics['predictions'],\n","                    average='weighted',\n","                    zero_division=0\n","                )\n","\n","                val_metrics.update({\n","                    'precision': precision,\n","                    'recall': recall,\n","                    'f1': f1\n","                })\n","\n","                epoch_time = time.time() - epoch_start\n","\n","                epoch_metrics.append({\n","                    'epoch': epoch + 1,\n","                    'train': train_metrics,\n","                    'validation': val_metrics,\n","                    'time': epoch_time\n","                })\n","\n","                scheduler.step(val_metrics['accuracy'])\n","\n","                # best_val_loss = save_best_model(\n","                #     model, self.label_to_idx, self.config, val_metrics,\n","                #     epoch + 1, best_val_loss, \"best_model.pth\"\n","                # )\n","\n","                # if val_metrics['loss'] < best_val_loss:\n","                #     best_val_loss = val_metrics['loss']\n","                #     early_stop_counter = 0\n","                # else:\n","                #     early_stop_counter += 1\n","\n","                # Store whether this epoch improved the validation loss\n","\n","                improved = val_metrics['loss'] < best_val_loss\n","\n","                # Save the model if it's better (and update best_val_loss)\n","                best_val_loss = save_best_model(\n","                    model, self.label_to_idx, self.config, val_metrics,\n","                    epoch + 1, best_val_loss, \"best_model.pth\"\n","                )\n","\n","                # Update early stopping counter based on whether we improved\n","                if improved:\n","                    early_stop_counter = 0\n","                else:\n","                    early_stop_counter += 1\n","\n","\n","                if early_stop_counter >= patience:\n","                    logger.info(\"Early stopping triggered.\")\n","                    break\n","\n","            return epoch_metrics\n","\n","        except Exception as e:\n","            logger.error(f\"Training failed: {str(e)}\")\n","            raise\n","\n","    # Saves training results and configurations for reproducibility and analysis.\n","    def track_training_results(self, config, metrics):\n","        final_epoch_metrics = metrics[-1]\n","        return {\n","            'timestamp': datetime.now().isoformat(),\n","            'configuration': {\n","                'learning_rate': config['hyperparameters']['learning_rate'],\n","                'batch_size': config['hyperparameters']['batch_size'],\n","                'image_size': config['hyperparameters']['image_size'],\n","                'num_epochs': config['hyperparameters']['num_epochs']\n","            },\n","            'performance': {\n","                'final_accuracy': final_epoch_metrics['validation']['accuracy'],\n","                'final_loss': final_epoch_metrics['validation']['loss'],\n","                'precision': final_epoch_metrics['validation']['precision'],\n","                'recall': final_epoch_metrics['validation']['recall'],\n","                'f1_score': final_epoch_metrics['validation']['f1'],\n","                'training_time': final_epoch_metrics['time']\n","            }\n","        }\n","\n","def objective(trial, base_config):\n","    \"\"\"\n","    Objective function for Optuna optimization.\n","    Trains a model with parameters suggested by Optuna and returns validation metrics.\n","    \"\"\"\n","    # Suggest hyperparameters\n","    current_config = base_config.copy()\n","    current_config['hyperparameters'].update({\n","        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True),\n","        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64, 128, 256]),\n","        'image_size': trial.suggest_categorical('image_size', [400]), # use only 400px images\n","        'num_epochs': 50  # Set a high number, we'll use early stopping\n","    })\n","\n","    # Create trainer with the suggested parameters\n","    trainer = ModelTrainer(current_config)\n","\n","    # Modify the train method to work with pruning\n","    metrics = []\n","    patience = 5\n","    best_val_loss = float('inf')\n","    early_stop_counter = 0\n","\n","    # Create data loaders and model\n","    train_transform, val_transform = trainer._create_transforms()\n","    train_loader, validation_loader, classes = trainer._create_dataloaders(\n","        train_transform, val_transform)\n","    model = trainer._create_model(len(classes))\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam([\n","        {'params': model.fc.parameters(),\n","        'lr': current_config['hyperparameters']['learning_rate'] * 10},\n","        {'params': model.layer4.parameters(),\n","        'lr': current_config['hyperparameters']['learning_rate']}\n","    ])\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, mode='max', patience=1, factor=0.1)\n","\n","    # Train for specified number of epochs with pruning checks\n","    for epoch in range(current_config['hyperparameters']['num_epochs']):\n","        epoch_start = time.time()\n","\n","        train_metrics = trainer._train_epoch(model, train_loader, criterion, optimizer)\n","        clear_gpu_memory()\n","        val_metrics = trainer._validate(model, validation_loader, criterion)\n","\n","        precision, recall, f1, _ = precision_recall_fscore_support(\n","            val_metrics['labels'],\n","            val_metrics['predictions'],\n","            average='weighted',\n","            zero_division=0\n","        )\n","\n","        val_metrics.update({\n","            'precision': precision,\n","            'recall': recall,\n","            'f1': f1\n","        })\n","\n","        epoch_time = time.time() - epoch_start\n","\n","        metrics.append({\n","            'epoch': epoch + 1,\n","            'train': train_metrics,\n","            'validation': val_metrics,\n","            'time': epoch_time\n","        })\n","\n","        scheduler.step(val_metrics['accuracy'])\n","\n","        # Report intermediate value for pruning\n","        trial.report(val_metrics['f1'], epoch)\n","\n","        # Check if trial should be pruned\n","        if trial.should_prune():\n","            raise optuna.exceptions.TrialPruned()\n","\n","        # Early stopping logic\n","        improved = val_metrics['loss'] < best_val_loss\n","        if improved:\n","            best_val_loss = val_metrics['loss']\n","            early_stop_counter = 0\n","        else:\n","            early_stop_counter += 1\n","\n","        if early_stop_counter >= patience:\n","            logger.info(f\"Trial {trial.number}: Early stopping triggered at epoch {epoch+1}\")\n","            break\n","\n","    # Save model if needed\n","    if hasattr(trainer, 'label_to_idx'):\n","        trainer.label_to_idx = trainer._create_dataloaders(train_transform, val_transform)[1].dataset.label_to_idx\n","        save_best_model(\n","            model, trainer.label_to_idx, current_config, val_metrics,\n","            len(metrics), best_val_loss, \"best_model.pth\"\n","        )\n","\n","    # Log the trial results to a file\n","    final_metrics = metrics[-1]['validation']\n","    trial_result = {\n","        'trial_number': trial.number,\n","        'timestamp': datetime.now().isoformat(),\n","        'parameters': {\n","            'learning_rate': current_config['hyperparameters']['learning_rate'],\n","            'batch_size': current_config['hyperparameters']['batch_size'],\n","            'image_size': current_config['hyperparameters']['image_size'],\n","            'actual_epochs': len(metrics)\n","        },\n","        'metrics': {\n","            'accuracy': final_metrics['accuracy'],\n","            'loss': final_metrics['loss'],\n","            'precision': final_metrics['precision'],\n","            'recall': final_metrics['recall'],\n","            'f1': final_metrics['f1']\n","        }\n","    }\n","\n","    # Save trial results to txt file\n","    results_file = os.path.join(base_config['paths']['absolute_path'], 'optuna_trials.txt')\n","    with open(results_file, 'a') as f:\n","        f.write(json.dumps(trial_result) + '\\n')\n","\n","    # Return the value to optimize (higher is better)\n","    return final_metrics['f1']  # Optimize for F1 score\n","\n","def run_bayesian_optimization(base_config, n_trials=100, study_name=\"resnet_optimization\"):\n","    \"\"\"\n","    Performs Bayesian optimization using Optuna for hyperparameter tuning.\n","    - Creates a study and optimizes the objective function\n","    - Saves the best parameters and study results\n","    \"\"\"\n","    # Create study directory\n","    study_dir = os.path.join(base_config['paths']['absolute_path'], 'optuna_studies')\n","    os.makedirs(study_dir, exist_ok=True)\n","\n","    # Create a pruner\n","    pruner = optuna.pruners.SuccessiveHalvingPruner(\n","        min_resource=5,        # Minimum number of epochs to run before pruning\n","        reduction_factor=4,    # Reduction factor for pruning\n","        min_early_stopping_rate=0  # Minimum early stopping rate\n","    )\n","\n","    # Create a new study\n","    storage_path = f\"sqlite:///{os.path.join(study_dir, f'{study_name}.db')}\"\n","    try:\n","        study = optuna.create_study(\n","            study_name=study_name,\n","            storage=storage_path,\n","            load_if_exists=True,\n","            direction=\"maximize\",  # Maximize F1 score\n","            sampler=optuna.samplers.TPESampler(seed=42),  # Use TPE sampler with fixed seed\n","            pruner=pruner  # Add the pruner here\n","        )\n","        logger.info(f\"Loaded existing study '{study_name}'\")\n","    except:\n","        study = optuna.create_study(\n","            study_name=study_name,\n","            storage=storage_path,\n","            direction=\"maximize\",  # Maximize F1 score\n","            sampler=optuna.samplers.TPESampler(seed=42),  # Use TPE sampler with fixed seed\n","            pruner=pruner  # Add the pruner here\n","        )\n","        logger.info(f\"Created new study '{study_name}'\")\n","\n","    # Optimize the study\n","    study.optimize(lambda trial: objective(trial, base_config), n_trials=n_trials)\n","\n","    # Get best trial and parameters\n","    best_trial = study.best_trial\n","    best_params = best_trial.params\n","\n","    # Save best parameters\n","    best_params_file = os.path.join(study_dir, 'best_params.json')\n","    with open(best_params_file, 'w') as f:\n","        json.dump({\n","            'best_params': best_params,\n","            'best_value': best_trial.value,\n","            'timestamp': datetime.now().isoformat()\n","        }, f, indent=2)\n","\n","    # Create a summary report\n","    trials_df = study.trials_dataframe()\n","    summary = {\n","        'study_name': study_name,\n","        'n_trials': n_trials,\n","        'best_params': best_params,\n","        'best_value': best_trial.value,\n","        'completed_trials': len(study.get_trials(states=[TrialState.COMPLETE])),\n","        'pruned_trials': len(study.get_trials(states=[TrialState.PRUNED])),\n","        'failed_trials': len(study.get_trials(states=[TrialState.FAIL]))\n","    }\n","\n","    # Save summary\n","    summary_file = os.path.join(study_dir, 'study_summary.json')\n","    with open(summary_file, 'w') as f:\n","        json.dump(summary, f, indent=2)\n","\n","    logger.info(f\"Best parameters: {best_params}\")\n","    logger.info(f\"Best F1 score: {best_trial.value}\")\n","\n","    return study, best_params\n","\n","def main():\n","    \"\"\"\n","    The main entry point for running the training pipeline with Bayesian optimization.\n","    \"\"\"\n","    # Base configuration\n","    base_config = {\n","        'paths': {\n","            'absolute_path': \"/content/gdrive/My Drive/Projects/Multimodal-Ecommerce/\",\n","            'dataset_path': \"/content/gdrive/My Drive/Projects/Multimodal-Ecommerce/Datasets/\"\n","        },\n","        'filenames': {\n","            'train_file': 'train_set_400.csv',\n","            'validation_file': 'validation_set_400.csv'\n","        },\n","        'columns': {\n","            'feature_col': 'Image',\n","            'label_col': 'Category'\n","        },\n","        'hyperparameters': {  # Default values\n","            'learning_rate': 1e-4,\n","            'num_epochs': 50,  # Set high, we'll use early stopping\n","            'batch_size': 32,\n","            'image_size': 400\n","        }\n","    }\n","\n","    try:\n","        # Create necessary directories\n","        os.makedirs(base_config['paths']['absolute_path'], exist_ok=True)\n","        os.makedirs(base_config['paths']['dataset_path'], exist_ok=True)\n","\n","        # Reset the optuna_trials.txt file\n","        results_file = os.path.join(base_config['paths']['absolute_path'], 'optuna_trials.txt')\n","        with open(results_file, 'w') as f:\n","            f.write(\"# Optuna Trials Results\\n\")\n","            f.write(\"# Format: One JSON object per line\\n\")\n","            f.write(\"# Created: \" + datetime.now().isoformat() + \"\\n\\n\")\n","\n","        # Run Bayesian optimization\n","        study, best_params = run_bayesian_optimization(base_config, n_trials=100)\n","\n","        # Train the final model with the best parameters\n","        final_config = base_config.copy()\n","        final_config['hyperparameters'].update(best_params)\n","\n","        logger.info(\"Training final model with best parameters...\")\n","        final_trainer = ModelTrainer(final_config)\n","        final_metrics = final_trainer.train(patience=10)  # More patience for final model\n","\n","        # Save the final model and results\n","        final_results = final_trainer.track_training_results(final_config, final_metrics)\n","        final_results_file = os.path.join(base_config['paths']['absolute_path'], 'final_model_results.json')\n","        with open(final_results_file, 'w') as f:\n","            json.dump(final_results, f, indent=2)\n","\n","        logger.info(\"\\nBayesian Optimization Completed!\")\n","        logger.info(f\"Final model trained with best parameters: {best_params}\")\n","        logger.info(f\"Check results in {base_config['paths']['absolute_path']}\")\n","\n","    except Exception as e:\n","        logger.error(f\"Error in main: {str(e)}\")\n","        raise\n","\n","if __name__ == \"__main__\":\n","    main()"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","import pandas as pd\n","import os\n","import time\n","import json\n","import logging\n","from tqdm import tqdm\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# Set up logging\n","logging.basicConfig(\n","    level=logging.INFO,\n","    format='%(asctime)s - %(levelname)s - %(message)s',\n","    handlers=[\n","        logging.FileHandler('prediction.log'),\n","        logging.StreamHandler()\n","    ]\n",")\n","logger = logging.getLogger(__name__)\n","\n","# Paths\n","BASE_PATH = \"/content/gdrive/My Drive/Projects/Multimodal-Ecommerce/\"\n","DATASET_PATH = \"/content/gdrive/My Drive/Projects/Multimodal-Ecommerce/Datasets/\"\n","MODEL_PATH = os.path.join(BASE_PATH, \"ResNet-with-pruning/ResNet-Trained-Models/model_lr_5.936234651371578e-05_bs_16_es_400.pth\")\n","LABEL_TO_IDX_PATH = os.path.join(BASE_PATH, \"ResNet-with-pruning/ResNet-Trained-Models/model_lr_5.936234651371578e-05_bs_16_es_400_label_to_idx.json\")\n","TEST_FILE = os.path.join(DATASET_PATH, \"test_set_400.csv\")\n","OUTPUT_FILE = os.path.join(DATASET_PATH, \"test_set_400_with_predictions.csv\")\n","\n","class TestImageDataset(Dataset):\n","    \"\"\"Dataset for test images\"\"\"\n","\n","    def __init__(self, csv_file, transform=None):\n","        self.data = pd.read_csv(csv_file)\n","        self.transform = transform\n","        self.dataset_path = DATASET_PATH\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def _get_local_path_from_url(self, url):\n","        \"\"\"Convert URL to local file path\"\"\"\n","        filename = url.split('/')[-1]\n","        folder = url.split('/')[-2]\n","        local_path = os.path.join(self.dataset_path, folder, filename)\n","        return local_path\n","\n","    def __getitem__(self, idx):\n","        try:\n","            img_url = self.data.iloc[idx]['Image']  # Assuming 'Image' is the column with image URLs\n","\n","            # Get local path from URL\n","            local_path = self._get_local_path_from_url(img_url)\n","\n","            # Load image\n","            img = Image.open(local_path).convert('RGB')\n","\n","            if self.transform:\n","                img = self.transform(img)\n","\n","            return img, idx  # Return image and index\n","\n","        except Exception as e:\n","            logger.error(f\"Error loading image at index {idx}: {str(e)}\")\n","            logger.error(f\"URL: {img_url}, Local path: {local_path}\")\n","            raise\n","\n","def load_model(model_path, label_to_idx_path, device):\n","    \"\"\"Load the trained model and label mapping\"\"\"\n","    # Load label to index mapping\n","    with open(label_to_idx_path, 'r') as f:\n","        label_to_idx = json.load(f)\n","\n","    # Print original mapping for debugging\n","    logger.info(f\"Original label_to_idx: {label_to_idx}\")\n","\n","    # Create inverse mapping (index to label)\n","    # Handle both string and integer keys\n","    idx_to_label = {}\n","    for label, idx in label_to_idx.items():\n","        if isinstance(idx, str):\n","            idx_to_label[int(idx)] = label\n","        else:\n","            idx_to_label[idx] = label\n","\n","    logger.info(f\"Created idx_to_label mapping with {len(idx_to_label)} entries\")\n","    logger.info(f\"Sample mapping: {list(idx_to_label.items())[:5]}\")\n","\n","    # Create model architecture (same as training)\n","    num_classes = len(label_to_idx)\n","    logger.info(f\"Number of classes: {num_classes}\")\n","\n","    model = models.resnet50(weights=None)  # No need for pretrained weights as we'll load our own\n","    model.fc = nn.Sequential(\n","        nn.Dropout(0.5),\n","        nn.Linear(model.fc.in_features, num_classes)\n","    )\n","\n","    # Load trained weights\n","    model.load_state_dict(torch.load(model_path, map_location=device))\n","    model = model.to(device)\n","    model.eval()  # Set to evaluation mode\n","\n","    return model, idx_to_label\n","\n","def predict():\n","    \"\"\"Make predictions on test set and save results\"\"\"\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    logger.info(f\"Using device: {device}\")\n","\n","    # Load model and mappings\n","    logger.info(\"Loading model...\")\n","    model, idx_to_label = load_model(MODEL_PATH, LABEL_TO_IDX_PATH, device)\n","\n","    # Create test data transforms (same as validation transforms during training)\n","    test_transform = transforms.Compose([\n","        transforms.Resize((400, 400)),  # Same as model's image_size\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                             std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    # Create test dataset and dataloader\n","    test_dataset = TestImageDataset(TEST_FILE, transform=test_transform)\n","    test_loader = DataLoader(\n","        test_dataset,\n","        batch_size=32,  # Can use larger batch size for inference\n","        shuffle=False,\n","        num_workers=min(4, os.cpu_count() or 1),\n","        pin_memory=True\n","    )\n","\n","    # Load test data\n","    test_df = pd.read_csv(TEST_FILE)\n","    predictions = [\"\"] * len(test_df)  # Initialize prediction list\n","\n","    # Start timing\n","    start_time = time.time()\n","\n","    # Make predictions\n","    logger.info(\"Making predictions...\")\n","    with torch.no_grad():  # No need to track gradients for inference\n","        for inputs, indices in tqdm(test_loader, desc=\"Predicting\"):\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            _, predicted_indices = torch.max(outputs, 1)\n","\n","            # Convert predicted indices to labels\n","            for i, idx in enumerate(indices):\n","                pred_idx = predicted_indices[i].item()\n","                if pred_idx in idx_to_label:\n","                    predictions[idx] = idx_to_label[pred_idx]\n","                else:\n","                    # Debugging info for unknown indices\n","                    logger.warning(f\"Unknown index: {pred_idx}, not found in mapping\")\n","                    predictions[idx] = f\"Unknown-{pred_idx}\"\n","\n","    # Calculate execution time and cost\n","    execution_time = time.time() - start_time\n","    prediction_cost = 0.000281392488 * execution_time\n","    print(f\"Prediction time: {execution_time:.2f} seconds\")\n","    print(f\"Prediction cost: ${prediction_cost:.2f}\")\n","\n","    # Add predictions to dataframe\n","    test_df['ResNet-50-Predictions-400'] = predictions\n","\n","    # Save updated dataframe\n","    test_df.to_csv(OUTPUT_FILE, index=False)\n","    logger.info(f\"Predictions saved to {OUTPUT_FILE}\")\n","\n","    # Show sample of predictions\n","    sample_size = min(10, len(test_df))\n","    logger.info(f\"\\nSample of {sample_size} predictions:\")\n","    sample = test_df.sample(sample_size)\n","    for _, row in sample.iterrows():\n","        logger.info(f\"Image: {row['Image'].split('/')[-1]}, Predicted: {row['ResNet-50-Predictions-400']}\")\n","\n","    # Calculate basic statistics\n","    category_counts = test_df['ResNet-50-Predictions-400'].value_counts()\n","    logger.info(f\"\\nPrediction distribution:\")\n","    logger.info(category_counts)\n","\n","    # Count unknown predictions\n","    unknown_count = sum(1 for pred in predictions if 'Unknown' in str(pred))\n","    logger.info(f\"Number of unknown predictions: {unknown_count} ({unknown_count/len(predictions)*100:.2f}%)\")\n","\n","if __name__ == \"__main__\":\n","    predict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jSfQNMbobkM9","executionInfo":{"status":"ok","timestamp":1744991179249,"user_tz":-180,"elapsed":113197,"user":{"displayName":"Konstantinos Roumeliotis","userId":"17264923090131634662"}},"outputId":"4e1bcab5-9651-40c6-b865-308b432765ce"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]},{"output_type":"stream","name":"stderr","text":["Predicting: 100%|██████████| 6/6 [01:02<00:00, 10.44s/it]"]},{"output_type":"stream","name":"stdout","text":["Prediction time: 62.66 seconds\n","Prediction cost: $0.02\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"3IPjJXwmv-zs"}}]}